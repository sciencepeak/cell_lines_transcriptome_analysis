---
title: "A good title to conceive"
author: "Author: Old Vegetable Bird"
date: "`r format(Sys.time(), '%F')`"
output:
    rmarkdown::html_document:
        theme: readable
        highlight: textmate
        df_print: paged
---

# initial settings

```{r warning=F, message=F}
rm(list = ls())
ptm <- proc.time()
# proc.time() - ptm
options(stringsAsFactors = F)
library("magrittr")
library("readxl")
library("edgeR")
library("limma")
library("R.utils")
library("hash")
```

# runtime parameters

```{r}
prior_count <- 0.001 # edgeR cpm
round_digit <- 3 # round the dataframe
```

# Set up input and output files and directories.

```{r}
grouping_path <- file.path("..", "01_cloud_workflow", "metadata", "samples_cell_lines_batch_both_SampleGroup.xlsx")
expression_path <- file.path(".", "intermediate_files", "expr_mat.raw_count.csv.bz2")

output_directory <- file.path(".", "intermediate_files")

output_csv_names <- c("expr_mat.log2_cpm.csv",
                      "expr_mat.log2_cpm.BE_adj.csv",
                      "expr_mat.log2_cpm.BE_adj.filtered.csv",
                      "expr_mat.log2_cpm.BE_adj.filtered.non_IQR_max.csv")
names(output_csv_names) <- c("log2_cpm",
                             "log2_cpm.BE_adj",
                             "log2_cpm.BE_adj.filtered",
                             "log2_cpm.BE_adj.filtered.non_IQR_max")
```

# Read the files from hard disk.

```{r}
raw_expression_dataframe <- read.csv(expression_path, row.names = 1, check.names = F)

grouping_dataframe <- read_excel(grouping_path)

# The grouping information will be transformed to hash key:value pairs
grouping_hash <- hash::hash(keys = grouping_dataframe$File, values = grouping_dataframe$Batch)
```

# Normalization using cpm funcion in edgeR package

```{r}
# normalized_expression_dataframe <- cpm(raw_expression_dataframe, log = T, prior.count = prior_count) %>% as.data.frame
normalized_expression_dataframe <- raw_expression_dataframe %>%
    DGEList %>%
    calcNormFactors %>%
    cpm(., normalized.lib.sizes = TRUE, prior.count = prior_count, log = TRUE) %>%
    as.data.frame
```

# Remove batch effect using removeBatchEffect function in limma package

```{r}
batch_factor_vector <- hash::values(grouping_hash, keys = colnames(normalized_expression_dataframe))
batch_effect_removed_dataframe <-
    removeBatchEffect(normalized_expression_dataframe, batch = batch_factor_vector) %>%
    as.data.frame
```

# Remove weird genes such as pseudogenes and unconfirmed genes.

```{r}
all_genes <- rownames(batch_effect_removed_dataframe)

remaining_genes <- grep("^[A-Z][A-Z1-9]+[.][1-9]+", all_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("\\.", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^MT-*[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("hsa-mir", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^MIR\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNA\\d+[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNU\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNVU\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNY\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^HNRN", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^SNOR[A-Z]\\d+[A-Z1-9]*", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^LOC\\d+[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^LINC\\d+[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^SCARNA\\d+[A-Z1-9]*", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("[A-Z1-9]+-[A-Z1-9][A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)

# remove genes that are pseudo genes/unconfirmed
corrected_expression_dataframe <- batch_effect_removed_dataframe %>%
    .[remaining_genes, , drop = F]
```


# Filtered out genes that has low variability or max expression value.

compute IQR, max value, apply filters to the normalized and logarithmized gene expression dataframe

```{r}
temporary_expression_dataframe <- corrected_expression_dataframe

# Calculate the Interquartile Range (IQR), which is used to remove outliers.
IQR_vector <- apply(temporary_expression_dataframe, 1, IQR)

# find out the max expression value among samples for each gene.
max_expression_vector <- apply(temporary_expression_dataframe, 1, max)

# Apply some filters to the expression matrix.
# Ensure the expression of a gene has enough variation among samples.
# The variation is that the Interquartile Range (IQR) values must be greater than a threshold.
# The threshold for unlogarithmized CPM is 2.
# The threshold for base-2 logarithmized CPM is 1.

# Ensure the expression of a gene can not be too small,
# So the gene expression should surpass the threshold.
# The threshold for unlogarithmized CPM is 1.
# The threshold for base-2 logarithmized CPM is 0.

desired_row_index <- IQR_vector >= 1 & max_expression_vector >= 0
threshold_temporary_expression_dataframe <- temporary_expression_dataframe[desired_row_index, ]
threshold_temporary_expression_dataframe

filtered_expression_dataframe <- threshold_temporary_expression_dataframe
```

# Output three gene expression dataframes.

```{r}
output_dataframe_list <- list(normalized_expression_dataframe,
                              batch_effect_removed_dataframe,
                              filtered_expression_dataframe,
                              corrected_expression_dataframe) %>%
    set_names(., value = names(output_csv_names)) %>%
    lapply(., round, digits = round_digit)

for (i in names(output_csv_names)) {
    write.csv(output_dataframe_list[[i]],
              file = output_csv_names[[i]],
              quote = F,
              row.names = T)
    output_compressed_file_name <- bzip2(output_csv_names[[i]], compression = 9, overwrite = T)[1]
    
    file.rename(from = output_compressed_file_name,
                to = file.path(output_directory, output_compressed_file_name))
}
```


```{r}
proc.time() - ptm
```

