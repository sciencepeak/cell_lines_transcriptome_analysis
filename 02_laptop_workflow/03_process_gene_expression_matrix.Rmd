---
title: "A good title to conceive"
author: "Author: Old Vegetable Bird"
date: "`r format(Sys.time(), '%F')`"
output:
    rmarkdown::html_document:
        theme: readable
        highlight: textmate
        df_print: paged
---

# initial settings

```{r warning=F, message=F}
rm(list = ls())
ptm <- proc.time()
# proc.time() - ptm
options(stringsAsFactors = F)
library("magrittr")
library("readxl")
library("edgeR")
library("limma")
library("R.utils")
library("hash")
```

# runtime parameters

```{r}
prior_count <- 0.001 # edgeR cpm
round_digit <- 3 # round the dataframe
```

# Set up input and output files and directories.

```{r}
grouping_path <- file.path("..", "01_cloud_workflow", "metadata", "samples_cell_lines_batch_both_SampleGroup.xlsx")
expression_path <- file.path(".", "intermediate_files", "expression_matrix.raw_count.csv.bz2")

output_directory <- file.path(".", "intermediate_files")

output_csv_names <- c("expression_matrix.log2_cpm.csv",
                      "expression_matrix.log2_cpm.BE_removed.csv",
                      "expression_matrix.log2_cpm.BE_removed.filtered.csv")
names(output_csv_names) <- c("log2_cpm", "log2_cpm.BE_removed", "log2_cpm.BE_removed.filtered")
```

# Read the files from hard disk.

```{r}
raw_expression_dataframe <- read.csv(expression_path, row.names = 1, check.names = F)

grouping_dataframe <- read_excel(grouping_path)

# The grouping information will be transformed to hash key:value pairs
grouping_hash <- hash::hash(keys = grouping_dataframe$File, values = grouping_dataframe$Batch)
```

# Normalization using cpm funcion in edgeR package

```{r}
# normalized_expression_dataframe <- cpm(raw_expression_dataframe, log = T, prior.count = prior_count) %>% as.data.frame
normalized_expression_dataframe <- raw_expression_dataframe %>%
    DGEList %>%
    calcNormFactors %>%
    cpm(., normalized.lib.sizes = TRUE, prior.count = prior_count, log = TRUE) %>%
    as.data.frame
```

# Remove batch effect using removeBatchEffect function in limma package

```{r}
batch_factor_vector <- hash::values(grouping_hash, keys = colnames(normalized_expression_dataframe))
batch_effect_removed_dataframe <-
    removeBatchEffect(normalized_expression_dataframe, batch = batch_factor_vector) %>%
    as.data.frame
```

# Remove weird genes such as pseudogenes and unconfirmed genes.

```{r}
all_genes <- rownames(batch_effect_removed_dataframe)

remaining_genes <- grep("^[A-Z][A-Z1-9]+[.][1-9]+", all_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("\\.", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^MT-*[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("hsa-mir", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^MIR\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNA\\d+[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNU\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNVU\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^RNY\\d+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^HNRN", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^SNOR[A-Z]\\d+[A-Z1-9]*", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^LOC\\d+[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^LINC\\d+[A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("^SCARNA\\d+[A-Z1-9]*", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)
remaining_genes <- grep("[A-Z1-9]+-[A-Z1-9][A-Z1-9]+", remaining_genes, perl=TRUE, value=TRUE, invert=TRUE)

# remove genes that are pseudo genes/unconfirmed
corrected_expression_dataframe <- batch_effect_removed_dataframe %>%
    .[remaining_genes, , drop = F]
```

# Filtered out genes that has low variability or max expression value.

compute IQR, max value

```{r}
temporary_expression_dataframe <- corrected_expression_dataframe

temporary_expression_dataframe$IQR <- apply(corrected_expression_dataframe, 1, IQR)
temporary_expression_dataframe$max <- apply(corrected_expression_dataframe, 1, max)

#sort by IQR, because we are more interested in higher variance genes
temporary_expression_dataframe <- temporary_expression_dataframe %>%
    .[order(.$IQR, decreasing = T), ]

## remove gene with log2 CPM < 0, and also choose those with IQR >= 1
temporary_expression_dataframe <- temporary_expression_dataframe[temporary_expression_dataframe$max >= 0, ]
temporary_expression_dataframe <- temporary_expression_dataframe[temporary_expression_dataframe$IQR >= 1, ]

temporary_expression_dataframe$max <- NULL
temporary_expression_dataframe$IQR <-  NULL

# Remove the outlier
# temporary_expression_dataframe[, "M238-CTRL-1hr"] <- NULL

filtered_expression_dataframe <- temporary_expression_dataframe
```

# Output three gene expression dataframes.

```{r}
output_dataframe_list <- list(normalized_expression_dataframe,
                              batch_effect_removed_dataframe,
                              filtered_expression_dataframe) %>%
    set_names(., value = names(output_csv_names)) %>%
    lapply(., round, digits = round_digit)

for (i in names(output_csv_names)) {
    write.csv(output_dataframe_list[[i]],
              file = output_csv_names[[i]],
              quote = F,
              row.names = T)
    output_compressed_file_name <- bzip2(output_csv_names[[i]], compression = 9, overwrite = T)[1]
    
    file.rename(from = output_compressed_file_name,
                to = file.path(output_directory, output_compressed_file_name))
}
```


```{r}
proc.time() - ptm
```

